# 设计文档

## 目标

围绕初始给定的主题，组建由多个 AI agent 组成的小组，进行持续多轮客户可控的头脑风暴。

## 名词解释

- **客户**：使用本产品的用户，负责提供讨论主题和必要信息，可能会参与到讨论中。
- **组织者**：负责组织和管理讨论过程的角色，由系统程序代码及大语言模型（简称 LLM）配合实现。
- **轮次**：每一轮讨论持续一定时长（事先设定），期间 agent 轮流发言，客户可随时请求暂停讨论。
- **Agent**：基于 LLM 的 AI 代理，负责在讨论中轮流发言。每个 agent 都有其角色设定，体现为 System Prompt 及语言模型的参数设置。
- **角色**：每个 agent 在讨论中的身份和专长设定，例如“经济学家”、“技术专家”、“资深工程师”等。

## 需求

- 在每一轮开始前
  - 确定此轮讨论的时长（初始由客户设定，其后的轮次由组织者根据此前轮次的讨论局面酌情调整）
  - 询问客户是否需要调整讨论主题，并引导客户补充必要的信息。
  - 如果不是第一轮，根据上一轮所有 agent 的表现评估及打分，淘汰部分 agent。
  - 根据讨论主题及相关信息，酌情安排（或补充）一定数量的新 agent，明确其角色与关注点（并设置相关 LLM API 参数及 System Prompt）
- 在每一轮讨论中
  - 组织者将上一轮讨论的总结作为本轮讨论的第一条发言
  - 轮流让每个 agent 发言。（agent 也可选择跳过此轮发言）
  - 客户可随时请求暂停讨论，在等待当前 agent 说完后，可以作出以下交互：
    - 以发言方式提供任何补充信息或回应其它 agent 的发言
    - 移除某个 agent（保留其既有发言，但后续退出讨论）
    - 添加新的 agent 加入讨论（以自然语言方式描述这个角色）
      - 系统根据客户的描述，自动生成 agent 角色（设置相关参数及 System Prompt）
    - 恢复暂停的讨论（让 agent 继续进行连续的讨论）
- 在每一轮结束后
  - 组织者总结这一轮的讨论，呈现给客户，并以组织者的发言形式作为下一轮讨论的起始信息。
    - 为确保后续的讨论能在既有轮次的基础上深入，组织者调用 LLM 进行总结的 prompt 须精心设计。
  - 评估每一个 agent 的表现并打分（10 分制），呈现给客户。（对 agent 不可见）

## 实现要点

- 最终交付的产品完全使用浏览器作为运行环境，没有服务端。主体代码使用 JS（而非 TypeScript）。
  - 讨论过程及重要的输出（比如 总结、此轮的 Agent 表现评估），以 Markdown 格式保存到浏览器本地用户授权的路径下。
    - Markdown 文件应具备用户可读性，并随着讨论的进行持续更新。
    - 每一轮次生成一个单独的 .md 文件。
  - 在所有需要用户输入的环节（比如 讨论主题、补充信息、介入进行中的讨论），客户除使用浏览器的原生输入框输入外，还可将输入写入一个特定的文件中（便于客户不依赖本机浏览器实例进行跨端介入）。
    - 系统在等待用户输入时，除接收浏览器交互输入外，同时检查此文件的更新，文件内容作为客户输入。
    - 只有在读取到的文件内容包含约定的结尾标志后，才将其视为有效输入，否则继续检查文件的更新。
    - 每次使用完此文件后，清空文件内容。用户的输入内容应完整呈现在讨论过程的 Markdown 文件中。
  - 系统可通过读取用户授权的本地路径下的文件，继续一个此前中断的讨论。
- 确保绝大部分代码可由开发工具配合 AI 插件进行自动化验证及测试，这些环节不应依赖浏览器。
- 主流程和 agent 使用预先分别配置的云端语言模型（配置 OpenAI 兼容 API 的 URL 前缀、模型名、API 参数 等）
  - 配置保存在浏览器本地用户授权的路径下。
- 只在必要的时候（比如组织者的关键评估或决策）才调用云端语言模型，讨论控制的主流程由代码逻辑实现。这部分代码应高度抽象（调用模块化的细节执行流程代码），易于后续由 LLM 对这一控制流程进行迭代优化。

## 详细设计

Prompt: 请根据以上概要设计，写一份[详细设计文档](implementation.md)，详尽程度以能直接指导编码为原则（但不用提供具体代码）。

# 设计文档

## 目标

围绕初始给定的主题，组建由多个 AI agent 参与的小组，进行持续多轮客户可参与的头脑风暴。

## 名词解释

- **客户**：使用本产品的用户，负责提供讨论主题和必要信息，可能会参与到讨论中。
- **组织者**：负责组织和管理讨论过程，并在每一轮讨论结束后进行总结评估的角色。
- **轮次**：每一轮讨论持续一定长度（事先设定），期间 agent 轮流发言，客户可随时加入讨论。
- **Agent**：由 LLM 驱动的 AI 代理，在讨论中遵照组织者的安排发言。每个 agent 都有其角色设定，体现为参数配置（System Prompt 及语言模型的参数）。
- **角色**：每个 agent 在讨论中的身份和专长设定，例如“经济学家”、“技术专家”、“资深工程师”等。

## 需求

- 在每一轮开始前
  - 确定此轮讨论的时长（初始由客户设定，其后的轮次由组织者根据此前轮次的讨论局面酌情调整）
  - 询问客户是否需要调整讨论主题，并引导客户补充必要的信息。
  - 如果不是第一轮，则根据上一轮每一个 agent 的表现评估及打分，分别决定是否淘汰，微调其角色参数，或是 保持不变。
  - 根据讨论主题及相关信息，酌情安排（或补充）一定数量的新 agent，明确其角色与关注点。
- 在每一轮讨论中
  - 组织者将上一轮讨论的总结作为本轮讨论的第一条发言
  - 轮流让每个 agent 发言。（agent 也可选择跳过此轮发言）
  - 客户可随时请求暂停讨论，在等待当前 agent 说完后，可以作出以下交互：
    - 以发言方式提供任何补充信息或回应其它 agent 的发言
    - 移除某个 agent（保留其既有发言，但后续退出讨论）
    - 添加新的 agent 加入讨论（以自然语言方式描述这个角色）
      - 系统根据客户的描述，自动生成 agent 角色（设置相关参数及 System Prompt）
    - 恢复暂停的讨论（让 agent 继续进行连续的讨论）
- 在每一轮结束后
  - 组织者总结这一轮的讨论，呈现给客户，并以组织者的发言形式作为下一轮讨论的起始信息。
    - 为确保后续的讨论能在既有轮次的基础上深入，组织者调用 LLM 进行总结的 prompt 须精心设计。
  - 评估每一个 agent 的表现并打分（10 分制），呈现给客户。（对 agent 不可见）

## 实现要点

- 最终交付的产品完全使用浏览器作为运行环境，没有服务端。
- 确保代码可由开发工具配合 AI 插件进行自动化验证及测试，测试环境不应依赖浏览器。
- 主流程和 agent 使用预先分别配置的云端语言模型（配置 OpenAI 兼容 API 的 URL 前缀、模型名、API 参数 等）。
- 只在必要的时候（比如组织者的关键评估或决策）才调用云端语言模型，讨论控制的主流程由代码逻辑实现。这部分代码应高度抽象（调用模块化的细节执行流程代码），易于后续由 LLM 对这一控制流程进行迭代优化。

## 详细设计

Prompt: 请根据以上概要设计，写一份[详细设计文档](implementation.md)，详尽程度以能直接指导编码为原则（但不用提供具体代码）
